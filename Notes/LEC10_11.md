# BOOK

`A more useful internal representation is one based on the extended relational algebra.`

**SQL**对用户易读, 但是对系统来说, **extended relational algebra扩展关系代数**更友好.

1. 用户输入: 给定*Query*
2. translation process: 解析语句并构建一个**parse-tree**
3. 翻译为**relational-algebra expression**
4. ...

- 15.1: `how to evaluate individual operations in a query plan and how to estimate their cost`
- 15.2: `how we measure the cost of a query`
- 15.3~15.6: `the evaluation of individual relational-algebra operations`
- 15.7: `examine how to coordinate the execution of multiple operations in a query evaluation plan, in particular, how to use pipelined operations to avoid writing intermediate results to disk.`
- 16: `query optimization`

## 15.1 & 15.2

磁盘上, 块写入通常比块读取贵大约两倍, 因为磁盘系统写入后会读回扇区以校验写入是否成功(或者有日志系统的存在)

## 15.3

query processing中, **file scan**是开销最低的访问数据操作. 

### Selections Using File Scans and Indices

1. A1 (**linear search**): 这是最直接的方式同时也是最普适的方式, 系统扫描每个文件快, 并测试所有的记录来判断是否满足选择条件.
2. A2 (**clustering index, equality on key**) 
3. A3 (**clustering index, equality on non-key**), 和A2的差别在于可能获取多个结果从中选择
4. A4 (**secondary index, equality**), 带有二级索引的和A2, A3的差别在于需要查表`逻辑索引->物理地址`



回顾一下: `Index structures are referred to as access paths`, 前面学过**聚簇索引**和**非聚簇索引**, 主要是物理顺序和逻辑顺序是否有关联决定, 如果是非聚簇索引, 也叫做**二级索引**, 主要理由就是需要从逻辑索引再第二次翻译到物理上的地址.

使用了索引的扫描叫做索引扫描**index scans**.

为了查阅线性扫描的成本估计, 先解释几个参数

1. $h_i$: 表示B+树的高度, 虽然我们假设从根到叶子节点的访问路径中, 每经过一个节点都需要一个随机I/O操作, 但考虑现实中的优化器往往假设B+树的内部节点存在于内存buffer中, 而且通常不到1%的节点是非叶子节点, 所以成本可以简化为从根到叶节点的路径只有一个随机I/O(还不考虑聚簇索引B+树的prefetch优化), 公式中设置$h_i=1$即可.
2. $t_S$, $t_T$: 磁盘相关的参数, 前者是寻道的事件,后者应该是转完一个块数据量的时间
3. $b_r$: 一个关系在文件中的块数量

插入: B+树非叶子节点的数量估计, N: 总记录数, n: 节点可容纳的记录数量,  m∈(n/2, n), 假设每个节点实际容纳的记录数量(均值), 叶子节点的数量$N = m^h$, 总节点数量: $\frac{m^{h+1}-1}{m-1}$, 所以非叶子节点的占比是$\frac{m^h-1}{m^{h+1}-1} = \frac{N-1}{m*N-1} ≈ \frac{1}{m}$

详细的成本估计移步: [数据库系统](https://note.hobbitqia.cc/DB/db11/#file-scan)

### Selections Involving Comparisons





## sort

数据排序在数据库系统中发挥着重要作用，原因有二。

- 首先，SQL查询可以指定对输出进行排序。
- 其次，对于查询处理同样重要的是，如果首先对输入关系进行排序，那么就可以高效地执行一些关系操作，如连接。

因此，在第 15.5 节讨论连接操作之前，我们先在这里讨论排序。

我们可以通过在排序键上建立索引来对关系排序，然后使用该索引按排序顺序读取关系。但是，这样的过程只是通过索引对关系进行**逻辑排序**，而不是物理排序。因此，按排序顺序读取元组可能会导致对每条记录进行磁盘访问（disk seek plus block transfer），这可能会非常昂贵，因为记录数可能远远大于块数。因此，最好对记录进行物理排序。(意思就是乱序磁盘读取IO, 每次访问的时候都要访问一下磁盘, 如果是物理连续的,那么可以组织为若干次访问磁盘)

排序问题已经得到了广泛的研究，既包括完全适合主内存的关系，也包括大于内存的关系。在第一种情况下，可以使用标准排序技术，如快速排序。在这里，我们将讨论如何处理第二种情况。

### External Sort-Merge Algorithm

对内存中没有的关系进行排序称为**外部排序external sorting**。最常用的外部排序技术是**外部排序合并external sort–merge**算法。接下来我们将介绍外部排序合并算法。让 M 表示主内存缓冲区中可用于排序的块数，即可用主内存缓冲其内容的磁盘块数。

1. 在第一阶段，创建若干个`sorted runs`；每个`run`都已排序，但只包含关系中的部分记录。

```
i = 0;
repeat
  read M blocks of the relation, or the rest of the relation,
    whichever is smaller;
  sort the in-memory part of the relation;
  write the sorted data to run file R_i;
  i = i + 1;
until the end of the relation
```

1. 第二阶段是合并`runs`。暂时假设`runs`总数 N 小于 M，这样我们就能为每个`run`分配一个数据块，并留出空间容纳一个输出块。合并阶段的操作如下

```
read one block of each of the N files R_i into a buffer block in memory;
repeat
  choose the first tuple (in sort order) among all buffer blocks;
  write the tuple to the output, and delete it from the buffer block;
  if the buffer block of any run R_i is empty and not end-of-file(R_i)
    then read the next block of R_i into the buffer block;
until all input buffer blocks are empty
```

合并阶段的输出是排序关系。输出文件是缓冲文件，以减少磁盘写入操作的次数。前面的合并操作是标准内存排序合并算法所使用的双向合并的一般化；它合并 N 次运行，因此称为 **N 向合并(N-way merge)**。

一般来说，如果关系远大于内存，在第一阶段可能会生成M个或更多的`runs`，而在合并阶段不可能为每个`run`分配一个块。在这种情况下，合并操作会分多次进行。由于有足够的内存容纳M-1个输入缓冲区块，因此每次合并都可以将M-1个`runs`作为输入。

初始阶段是这样运行的： 合并前M-1次`runs`（如上文第 2 项所述），为下一次合并获取单次`run`。然后，以类似方式合并下一个M-1次`runs`，依此类推，直到处理完所有初始运行。此时，运行次数已减少了 M - 1 倍。如果减少后的运行次数仍大于或等于 M，则以第一遍创建的运行次数为输入，进行下一遍处理。每经过一次，运行次数就会减少 M - 1 倍。 每次重复的次数视需要而定，直到运行次数小于 M；最后经过一次，生成排序后的输出。

图 15.4 举例说明了外部排序合并的步骤。为便于说明，我们假设一个数据块中只包含一个元组（f_r = 1），并假设内存最多容纳三个数据块。在合并阶段，两个数据块用于输入，一个用于输出。

---

### Cost Analysis of External Sort-Merge

假设一个待排序文件的总blocks数量是$B_{r}$个, 内存最多允许排序*M*个blocks, 那么在第一个阶段, 我们需要准备$\frac{B_{r}}{M}$个`runs`, 此外第一阶段的吞吐blocks数量是$2 * B_{r}$

为了减少I/O次数, 假设第二阶段每个*pass*中, 从每个`runs`中取$B_{b}$个blocks, 设总*pass*的数量是*n*, 可以发现, 阶段二每次合并了$\frac{M}{B_{b}}-1$个`runs`, 意味着每轮*pass*总`runs`数量缩小$\frac{M}{B_{b}}-1$, 那么有$(\frac{M}{B_{b}}-1)^{n}=\frac{B_{r}}{M}$, 所以$n=log_{\frac{M}{B_{b}}-1}(\frac{B_{r}}{M})$

考虑每个*pass*的吞吐blocks数量, 也是两倍, 不考虑各种各样的因素, 我们保守估计应该是$2 * B_{r} * log_{\frac{M}{B_{b}}-1}(\frac{B_{r}}{M})$

所以整个排序的吞吐blocks数量是$2 * B_{r} * (log_{\frac{M}{B_{b}}-1}(\frac{B_{r}}{M}) + 1)$


## join

在本节中，我们将研究几种计算关系连接的算法，并分析它们各自的成本。

在这之前假设以下数据:

- Number of records of student $n_{student}$: 5000.
- Number of blocks of student: $b_{student}$ = 100.
- Number of records of takes: $n_{takes}$ = 10, 000.
- Number of blocks of takes: $b_{takes}$ = 400.

### Nested-Loop Join

符号: $r \Join_{\circ} s$, `r`称为**outer relation**, `s`称为**inner relation**, 其运算的伪代码如下:

```
for each tuple t_r in r do begin
  for each tuple t_s in s do begin
    test pair (t_r , t_s) to see if they satisfy the join condition θ
    if they do, add t_r · t_s to the result;
  end
end
```

其中`t_r · t_s`表示$t_r$和$t_s$属性值连接而成的元组. 与用于选择的线性文件扫描算法一样，嵌套循环连接算法不需要索引，而且无论连接条件是什么都可以使用。扩展该算法以计算自然连接是非常简单的，因为自然连接可以表示为一个 Theta 连接，然后通过投影消除重复属性。唯一需要做的改动是在将`t_r · t_s`元组添加到结果之前，额外删除它的重复属性。不难分析这个操作的开销会很高. 在缓冲区只能容纳每个关系的一个块的时候, 块的传输数量是$n_r * b_s  + b_r$

### Block Nested-Loop Join

伪代码:

```
for each block B_r of r do begin
  for each block B_s of s do begin
    for each tuple t_r in B_r do begin
      for each tuple t_s in B_s do begin
        test pair (t_r , t_s) to see if they satisfy the join condition
        if they do, add t_r · t_s to the result;
      end
    end
  end
end
```

缓冲区只能容纳各关系一个块时的传输数量: $b_r * b_s + b_r$

---

嵌套循环和分块嵌套循环程序的性能还可以进一步提高：

1. 如果自然连接或等连接中的连接属性构成了内部关系的键，那么对于每个外部关系元组，只要找到第一个匹配，内循环就可以终止。
2. 在块嵌套循环算法中，我们可以不使用磁盘块作为外部关系的阻塞单元，而是使用内存中能容纳的最大大小，同时为内部关系的缓冲区和输出留出足够的空间。换句话说，如果内存有 M 个区块，我们可以在 M - 2 个外部关系块，读取内部关系的每个块时，将其与外部关系的所有 M - 2 个外部关系块。这一变化将内部关系的扫描次数从 $b_r$ 减少到 $b_r/(M-2)$，其中 $b_r$ 是外部关系的块数。因此总成本为 $b_r∕(M-2) * b_s + b_r$块转移
3. 我们可以交替向前和向后扫描内循环。这种扫描方法会对磁盘块请求进行排序，这样就可以重复使用上一次扫描后缓冲区中剩余的数据，从而减少磁盘访问次数。
4. 如果内循环的连接属性上有索引，我们就可以用更高效的索引查找来代替文件扫描。第 15.5.3 节将介绍这种优化方法。

### Indexed Nested-Loop Join



# LEC

前面讲了下in-memory排序, 然后讲了external-sorting, 也就是书上看的.

## double buffer optimization

往常见识的执行流程是bpm请求从磁盘读入数据, 然后CPU再进行处理, 二者没有重叠的部分, 导致了系统响应时间比较长, 如果我们能够在CPU进行与运算的时候执行I/O, 让二者重叠, 那么就能很快的响应请求, 这就是**double buffer**的优化目的, 尽管它不会改变吞吐量.

## Aggregation

有时我们需要将多个元组（tuples）中的单个属性值聚合（collapse）成一个标量值（scalar value）。有两种实现方案:

1. 排序
2. 哈希

我们可以对排序后的数据进行聚合, 也可以在排序的核心函数里提前进行聚合, 不管哪一个, 都需要对数据提前排序, 这是一个耗时的操作, 所以我们有另外一个更快捷的方案, 哈希.

### Hashing Aggregate

如果所有的数据都能在内存中存放并操作, 那么这很简单, 对每一个记录, 检查对应的哈希桶是否已存在记录即可.

更需要思考的是`External Hashing Aggregate`, 仍然是分为两个步骤:

1. Partition, 根据第一个哈希函数, 将数据按照期望的key进行分组, 每个组分为一个区, 这样存到磁盘(如果内存不够的话)
2. Rehasing, 根据第二个哈希函数, 将之前分好组的数据, 按组进行重哈希, 这次哈希的key是我们想要统计的某个条目, 然后进行记录需要的内容

举个例子:

```sql
SELECT cid, AVG(s.gpa)
 FROM student AS s, enrolled AS e
 WHERE s.sid = e.sid
 GROUP BY cid
```

那么第一阶段我们会按照`cid`进行分区, 然后第二阶段从每个区里把匹配的数据聚合在一起, 放在内存哈希表中


# LEC11

## Join's output

决定join的输出: **Early Materialization**还是**Late Materialization** ?

早期物化的缺点是在query plan中, join的输出算子(父算子)很大概率不会用到完整的tuple的数据, 可能伴随着的就是投影算子; 但是好处在输出算子查询输出的时候不必等待**回表**(回到原始的表中查询数据)的I/O延迟, 响应时间会很短.

晚期物化是一种lazy operation, 在操作系统领域里非常的常见(COW, lazy allocation, on-demand page...), 但是在DBMS领域这说不上是一种优化, 如果是非列式存储的数据, 那么晚期物化不仅会带来高延迟的问题, 同时增加了很多磁盘的随机I/O.

如果我们考虑缓冲机制, 早期物化更可能因局部性而收益, 当我们进行join, 我们采取早期物化的策略, 那么join的结果很有可能会驻留在buffer或者其他缓冲区, 紧接着父算子就会尝试获取join后的数据, 而高速的在内存中读取缓存.

课上还提到了另外一个设计上的问题, 晚期物化会交错处理这类事务, 频繁不断的从I/O和执行中切换.

## join algorithm

假设以下语句:

```sql
SELECT R.id, S.cdate
 FROM R JOIN S
 ON R.id = S.id
 WHERE S.value > 100
```

关系R拥有m个tuples在M个pages(block)里, 关系S拥有n个tuples在N个pages(block)里, 我们关注的开销是I/Os次数.

### Nested Loop Join

```c
tuple r, s;
/** in disk */
for r in R:
  for s in S:
    if(s.id == r.id) emit
```

```c
tuple r, s;
block B_r, B_s;
/** in disk */
for B_r in R:
  for B_s in S:
  /** in memory */
    for r in B_r:
      for s in B_s:
        if(s.id == r.id) emit
```


假设buffers可容纳B个pages, 那么我们可以采取I/Os更少的策略:

1. 使用B-2个buffer page缓存每次读取*outer table*
2. 使用1个buffer page缓存每次读取*inner table*
3. 使用1个buffer page缓存每轮的输出


```c
tuple r, s;
page *p_r, p_s;
/** in disk */
for p_r[B-2] in R:
  for p_s in S:
    /** in memory */
    for r in p_r[B-2]:
      for s in p_s:
        if(s.id == r.id) emit
```

关于 ***Nested Loop Join*** 的优化, 我们的策略是尽可能让`outer table`的数据存放在缓冲池中, 并不断遍历`inner table`查询可join的tuple, 对`inner table`的访问来说十分低效, 粗暴.

如果我们为其在参与join字段的key上构建索引(一般来说都用现成的索引, 而没有为其重新建表), 那么就可以避免掉这样的暴力的轮询;

```c
tuple r, s;
for r in R:
  for tuple s = Index[r.id]:
    emit;
```

### Sort-Merge Join

考虑先对参与join的表进行排序, 然后采取双指针的方式去完成join操作, 算法比较好懂(不过仍然有一些edge需要判断), 主要的开销在于排序, 所以一般对已排好序的表或者说有排序的需求的表进行join的时候才会考虑这个方式.

### Hash Join

步骤分为建表和查询:

1. **Build**建表, 扫描`outer table`, 使用哈希函数构建以要join字段为key的哈希表
2. **Probe**查询, 扫描`inner table`, 使用哈希函数得到K, 然后查询第一阶段建的哈希表中是否有对应V, 从而完成join操作

补充的是, 这里建表的时候也有早/晚物化的选择; 

对第二阶段查询的优化可以用到前面提过的`Bloom Filter`, 我们不一定要在哈希表中进行实际的查询, 在建表的时候维护一个探测过滤器, 那么在查询的时候就可以提前得知是否有对应的表项, 这个优化也叫做**sideways information passing**.

和上一节学的外部排序一样, 还是需要解决内存中无法容纳整个哈希表的情况(我觉得选择早/晚物化的时候需要考虑到内存是否可容纳带有实际tuple数据的哈希表): **Grace Hash Join**, 策略如下:

建表阶段我们建两张哈希表, 对`outer/inner table`都以同样的哈希函数建立表, 然后对不同哈希表中相同位置的哈希桶做`nested loop join`操作, 如果存在单个哈希桶也太大的情况, 我们要用新的哈希函数继续切割划分.

整个过程的I/Os开销分析, 构建的时候我们要访问`outer/inner table`, 所以需要M+N次磁盘I/Os, (和物化策略有关系)建立的哈希表至少容纳二者的数据, 所以空间大小是O(N), 写回磁盘也需要M+N次I/Os;  查询的时候需要对所有哈希桶都做一次`nested loop join`, 相当于遍历整个哈希表, 所以需要读入整个哈希表, M+N次I/Os, 那么一共是3(M+N)次I/Os

# Question

1. 合并`runs`的阶段中, 为什么要预留一个输出块?
2. rehash阶段的第二个哈希函数是用来做什么的
3. 不断改进`Nested loop join`过程中, 出于什么考量我们期望尽可能将`outer table`存在缓冲池?
4. 在优化`Nested loop join`时, 我们为`inner table`建立索引, 而在`Hash join`中, 我们为`outer table`构建哈希索引, 二者差别是出于是什么考量?
5. 为什么总是流式处理较大的表, 而为较小表建索引? (流式处理即用完一个block就从内存中丢弃, 重新读取磁盘)

来回答我们的问题;

1. 在讨论prefetch优化对实验的效果时, 和同学深入的讨论到了os文件系统的读写文件, 在那里的结果告诉我: 如果我们能对要组织回磁盘或者写入到内存的数据预留缓冲区, 那么就可以做更多的事, 至少能保证放入到目的地(磁盘或者内存)的物理地址是连续的.
2. 我不知道
3. 可能需要更多的讨论, 比如csapp中介绍循环展开和缓存友好代码之类的一些主题, ... 看第五个问题
4. 课上来自CMU的学生给出了合理的答案, 不确定是否正确, 但是我认为足够解释.
5. 在`hash join`中`outer table`按习惯, 会更小, 因此构建出的哈希表也会更小, 更有可能适应内存, 而在使用`index nested loop join`时, `inner table`较大, 因此你会希望利用索引来加快每次对`outer key`的查询时间. 比如如果你在外层表使用了一个B+索引, 而内层循环有更多迭代, 那么总的查找时间将会更久, 所以最好是流式处理(用完一个block就从内存中丢弃, 重新读磁盘)较大的`table`

总结一下, 第一点需要直到的前提是按习惯`outer table`比`inner table`更小, 第二就是为较小的表建立索引, 会使索引表更小, 比如这里提到的哈希表, 会更容易存放整个表到内存中.